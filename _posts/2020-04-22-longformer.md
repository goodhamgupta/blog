---
toc: true
layout: post
description: Make transformers more efficient
author: Shubham Gupta
categories: [nlp, transformer, review, longformer]
image: images/longformer/training.png
title: 'LongFormer'
---

# Introduction

- Longformer is a paper by Allen AI which was referenced in DAIR's nlp newsletter(available [here](https://dair.ai/NLP_Newsletter_10_en/))
- It aims to solve the limitation of the number of tokens that can be processed simultaneously in the transformer architecture.

