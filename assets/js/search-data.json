{
  
    
        "post0": {
            "title": "LongFormer",
            "content": "Introduction . The NLP world had its ImageNet moment with the introduction of the Transformer in the paper Attention is All you Need. | The ability to be able to process multiple words/tokens in parallel and train models without labeled data(using self-attention) led to the creation of multiple models which gave us SOTA results on many interesting tasks such as Question Answering, Summarization, etc. | However, the biggest drawback is the Transformer architecture is the limitation it has on the number of tokens it can process at a once, due to exponentially increasing memory and compute requirements(typically about 512 tokens), causing the performance to deteriorate over large documents. | Longformer by the team at Allen AI aims to address this problem and demonstrate it’s application to do transfer learning for large documents. | Other approaches to are described in recent work such as Transformer XL, Blockwise, Reformer, etc. Their characteristics are mentioned below: | . . Key Contributions . Transformers are expensive because of the massive matrix operations involved in the self-attention step. Since each token can attend to every other token in the given input, we get a runtime of $O(n^2)$, where $n$ is the sequence length(typically 512 tokens). | LongFormer aims to solve this using a form of sparse attention and reducing the operational complexity to $O(n)$. They achieve this using the concept of the sliding window and dilated sliding window. | The authors also show how this attention pattern can be modified (using dilation and global attention) on a per-task basis, thereby allowing us to use a single model for all tasks rather than creating task-specific architectures. | . Attention Patterns . The attention patterns implemented are as follows: | . Sliding Window Attention . TLDR : Similar to kernels for CNN which apply a matrix operation to a set of pixels and move onto the next set, apply attention to tokens in current window only. | In this, we change the attention objective to only focus on the tokens that occur in a context window $w$. | Each token will be able to attend to $ frac{1}{2}w$ number of tokens to it’s left and right. | Question: But doesn’t this limit the number of tokens being taken into account to only the tokens in the window? Yes, it does. This is why we stack multiple layers of self-attention. As shown in the image below, the green neuron learns from the first 3 tokens(Lionel, Messi, is). However, the brown neuron learns from the green, yellow, and red neuron, who together learn from the first 5 tokens. This way, we can apply attention to long sequences(Lionel, Messi, is, the, true). | . | As with the CNN, we will have $l$ layers to this sliding window attention(multi-head attention) implemented to learn low level and high-level features. A balance should be found between the number of layers $l$(efficiency) and the window size $w$(model representation capacity). | . . Pros: Reduces computation from $O(n^2)$ to $O(n*w)$ i.e the computation complexity will only scale linearly now. . | Cons: To learn dependencies for a large sequence, we would either have to increase the window size $w$ or increase the number of layers $l$, both of which will cause an increase in the amount of memory and processing power required to train and test the model. . | . Dilated Sliding Window . TLDR: Use dilation instead of window attention i.e for some particular window size, take alternate elements while performing self-attention. | To solve the problem for long sequences, the authors propose that instead of considering all tokens in window $w$, consider alternate(or any number $d$)tokens instead. The range of tokens will now be $l * d * w$, which will be large for even a small value of $d$. . | Pros: This small change will allow us to cover a wider range of tokens without significant changes to the architecture. | Cons: Skipping tokens might lead to loss of information in the lower layers which will get propagated to the higher layers. This will lead to unstable training and poor model performance. | . Global Attention . TLDR: Use full attention for certain tokens depending on the task. This is an engineering choice. | In BERT style models, optimal representation for input sequence varies by task. For MLM, local context is used to predict the masked word | For classification, [CLS] token is used. | For QnA, the question is concatenated with the document to help model learn through self-attention. | . | The windowed and dilated attention is not flexible enough to learn task-specific representations. | Hence, for some tokens enable global tokens i.e at these tokens, all tokens in the sequence can attend to it. For classification, enable global attention on the [CLS] token. | Pros: Adding global attention improves performance for specific tasks. Since these tokens are limited in number, the complexity still stays at $O(n)$. | It also increases the representational power of the model. | . | . Linear Projections . TLDR: Use two sets of Q,K and V matrices, one for sliding window attention, one for global attention. | Attention is defined as: . Attention(Q,K,V)=softmax(QKTdk)V begin{aligned} Attention(Q,K,V) = softmax( frac{QK^T}{ sqrt{d_k}})V end{aligned}Attention(Q,K,V)=softmax(dk​​QKT​)V​ | We will use two different sets of Q,K and V matrices for sliding window and global attention. | $Q_g$, $K_g$, $V_g$ are initialized with $Q_s$, $K_s$, $V_s$ | . . Banded Matrix(Source) . Compressed Banded Matrix(Source) CUDA Kernels . One of the important and interesting contributions of this paper is the implementation of matrix multiplication via CUDA kernels. | In the dilated sliding window, the matrix formed is called a band matrix i.e there are diagonal bands of indices that have values and the other values are 0. | Implementing matrix operations for band matrices using native for loops and via frameworks is not easy and optimized. | The authors have provided custom CUDA kernels implemented using TVM for this banded matrix operations. | As demonstrated in the image below, the custom CUDA kernels have a significant impact on the time and memory consumption of the model. The kernels and implementation for the longformer are available here. | . LongFormer Performance Autoregressive Language Modelling . Estimate the probability of a token given its previous tokens/characters in an input sequence. | It is a fundamental task in natural language and all previous work use this task as their primary evaluation measure. | . Attention Pattern . In multi-head attention, each head computes a different score. | To get a good representation of all tokens, the authors propose that normal sliding window attention can be used for the lower layers, and dilated sliding window attention can be used the higher layers(top 1-2 layers). | The reasoning for this approach is that in the lower layers, the local context is more important, and in the upper layers, the global context is more important. Hence, it is acceptable to skip over a few tokens in the upper layers. | . Experimental Setup . Task and Datasets . The authors focus on character level modeling because the sequences are naturally longer than those of word-level language modeling. | Datasets that were used are text8 and enwik8. | . Training and Evaluation . The model was trained in multiple phases. The window and sequence length was increased in each phase. This is to allow local context from tokens to be learned efficiently. | Overall five training phases used, starting from the token length of 2048 to 23040 (45x more than vanilla BERT). | Two models were created for evaluation: Small model: 12 layers, 512 hidden size | Large model: 30 layers, 512 hidden sizes (2.5x larger) | . | During the model evaluation, the model can run on a sequence length of 32256(63x more than vanilla BERT). | . | . Results . . Longformer achieves SOTA using the small models with BPC of 1.10 and 1.00 for text8 and enwik8. | The large model was only tested on enwik8 due to the computational cost of training. | It’s also important to note that, while the large model did not achieve SOTA, it performs much better than it’s counterparts who have almost 2x more parameters. | . Pretraining and Finetuning . The LongFormer is trained to solve the tasks of classification, QA, and coreference resolution. | It is trained with MLM objective. | . Copy initialization trick . Since the MLM objective pretraining objective is expensive, the authors continue to train from the checkpoints of the RoBERTA model. | The attention mechanism is replaced with the new attention module. | For the position embeddings: RoBERTA has position embeddings for 512 tokens. | LongFormer can support position embeddings for 4096 tokens(larger for larger GPU) | To use the weight checkpoints from RoBERTA, instead of random initialization, copy the 512 position embeddings multiple times as analysis of the BERT attention heads showed a strong learned bias to attend to the local context. | . | . Pretraining . Apart from the datasets(Books corpus + English Wikipedia) used in RoBERTA, $ frac{1}{3}^{rd}$ Realnews dataset was added with tokens larger than 1200. | Both models(small and large) trained with varying gradient updates. | . . MLM BPC for RoBERTA with various model config Task-Specific Results . Main results are summarized below: | . LongFormer Task Specific Results The performance gain is high for tasks that require long contexts such as WikiHop and Hyperpartisan. | For TriviaQA, the improvement is small because the local context is often sufficient to answer the given question. | Similarly, gains in IMDB and OntoNotes are small(because of majority short reviews for IMDB and low distance between any two mentions for OntoNotes). | However, the LongFormer large model achieves SOTA on WikiHop and TriviaQA. | Using the large model also improves performance on HotpotQA. | . Conclusion . Overall, this was a fun read. The changes introduced in the attention mechanism are fairly simple but they yield very high-performance gains, paving the path to make these models useful in future applications. | Personally, and also as noted by the authors, I would like to see the performance of the LongFormer on the summarization task. | . References . Fantastic summary by Yannic Kilcher available here. | LongFormer paper available here | Dair.ai NLP newsletter available here | Open-sourced longformer code available here | .",
            "url": "https://goodhamgupta.github.io/blog/nlp/transformer/review/longformer/2020/05/11/longformer.html",
            "relUrl": "/nlp/transformer/review/longformer/2020/05/11/longformer.html",
            "date": " • May 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "TagLM",
            "content": "Introduction . This is the TagLM paper mentioned in Lecture 13 in the CS224N course title Semi-supervised sequence tagging with bidirectional language models . | This paper demonstrates how we can use context embeddings from BiLSTM models and use it for sequence labelling tasks . | . Paper Introduction . Typically, RNN are used only on labelled data to learn the context embeddings of words. . | Semi supervised approach used in this paper. . Train LM on large unlabelled corpus . | Compute embedding at each position in the sequence(LM embedding) . | Use embedding in supervised sequence tagging model . | . | Using both forward and backward embeddings gives better performance than using forward only LM. . | . TagLM . Overview . Extract word and LM embeddings for every token . | Prepare embedding by concatinating both embeddings . | se them in supervised sequence tagging model . | . Baseline . Baseline model is hierachical neural tagging model . | Obtain word and character embeddings. Concatenate them to form final embedding. . xk=[ck;wk]x_k = [c_k;w_k]xk​=[ck​;wk​] | Char embedding: Can be obtained via CNN or RNN . | Word embedding: Use pretrained embeddings . | Use multiple bidirectional RNN to learn context embedding . | For every token, concatenate forward and backward hidden states at each layer . | 2nd layer will use the above output and predict next hidden state . | Use GRU or LSTM depending on task . | Use output of final layer to predict score for each possible tag using dense layer . | Better to predict tags for full sequence than for a single token . | THEREFORE, add another layer with parameters for each label bigram. . | Compute sentence conditional random field loss(CRF) using forward-backward algorithm. . | Use Viterbi algorithm to find most likely sequence . . | LM embedding will be created by concatenating forward and backward embeddings. No parameter sharing between these two embeddings. . | . Experiments . Evaulation done on CoNLL 2003 NER and CoNLL 2000 chunking . | Lot of detail around model architecture and training methods. Skipping this for now. . | . Analysis . Second RNN captures interactions between task specific context . | Backward LM addition has significant performance gains . | Model size makes a difference. Using bigger CNN model lead to  0.3 percent improvement . | Also tried training the model JUST ON THE CoNLL data. Reduced model size . | Including embeddings from this model decreased performance compared to baseline system. . | Replacing task specific RNN with using LM embeddings with a dense layer and CRF reduced performance . | Improvement shown by transferring knowledge from other tasks almost disappers when the initial model is trained on a large dataset. . | . Summary . First method to incorporate contextual word embeddings using bidirectional networks. | Significantly better than other methods at the time that use other forms of transfer learning or joint learning on NER and and Chunking tasks. | It works well with unlabelled data from a different domain as well. | .",
            "url": "https://goodhamgupta.github.io/blog/nlp/language_model/review/2020/04/23/tag-lm.html",
            "relUrl": "/nlp/language_model/review/2020/04/23/tag-lm.html",
            "date": " • Apr 23, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "How much do you know?",
            "content": "Introduction . This is a new paper which explores the limits of using their new T5 titled How Much Knowledge Can You Pack Into The Parameters of a Language Model?. model in a context-free QA domain. . | As with the T5 model itself, it is very interesting to see these one-model-to-rule-them-all architectures as they exhibit some form of generalization. . | I found this paper from Adam Roberts twitter thread which is available here . | Core Idea: This paper will test two main things: . How well does the model create a knowledge base such that it can answer questions just based on this base and no other information. . | Do model with more parameters store more information? Measuring knowledge retreiving ability is used to check this point. . | . | . Paper Introduction . Reading Comprehension: Given a question and context, lookup and give the answer. . | Open domain question answering: Random context-independent questions. It is given entire context(all the information possible in the world) and the model is expected to deduce the answer. Open book exam. . | Here, problem is similar to open book exam + no context given at all. Model should retreive info from parameters and return the values. Closed book exam. . | T5: Treat every NLP task as text-to-text problem using encoder decoder Transformer. . | For natural questions dataset, evaluation is done as follows: . | First method: . Ignore all “unanswerable” and “long answer” type questions. . | model trained to output single answer . | Questions with answers longer than 5 tokens are ignored . | Answers normalized before comparsion . | Answer is correct if it matches any of the annotated answers . | . | Second method: . Considered correct only if model predicts all the answers correctly | . | For fine tuning, use AdaFactor Optimizer(need to read more about this one) . | . Results . SOTA on Natural Questions(NQ) and WebQuestions(WQ) dataset. Worst performance on TriviaQA(TQA). . | Performance increases with model size. . | Guu et all(2020) performs better than T5 on NQ and WQ. Need to read this paper as well. It . Retreives Revevant documents . | Answers questions in end-to-end fashion . | . | Closed-book model seem to perform on par with open-book models, leading to new research directions. . | For multiple answer type questions, T5 lower than SOTA BUT much better than baseline that was published with the paper. Therefore, T5 can perform well on these types of questions as well. . | . Drawbacks . Model is far too expensive to train. . | Open-book models provide some indication of what information was used to answer the problem. HOWEVER, T5 just has a distribution over parameters that cannot be interpreted. . | MLE does not gurantee the model will learn a fact. Therefore, difficult to ensure the model learns specific information during pre-training . | Measure and improve performance on difficult QA tasks like DROP, which needs reasoning ability. . | .",
            "url": "https://goodhamgupta.github.io/blog/nlp/language_model/review/2020/04/21/knowledge-lm.html",
            "relUrl": "/nlp/language_model/review/2020/04/21/knowledge-lm.html",
            "date": " • Apr 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Attention is all you need",
            "content": "Introduction . This paper review is following the blog from Jay Alammar’s blog on the Illustrated Transformer. The blog can be found here. | . Paper Introduction . New architecture based solely on attention mechanisms called Transformer. Gets rids of recurrent and convolution networks completely. . | Generally, RNN used to seq-to-seq tasks such as translation, language modelling, etc. . | Transformer allows for significant parallelization and relies only on attention. . | . Background . Self attention Attention to different positions of a sequence in order to compute a representation of the sequence. | . Model Architecture . Transformer uses the following: . Encoder decode mechanism . | Stacked self attention . | Point wise fully connected layer for encoder and decoder . | . . | . Encoder and decoder stacks . Encoder: 6 identical layers. 2 sub layers per layer . | First: multi-head self attention mechanism . | Second: Fully connected feed forward network . | Apply residual connection for each of the two laters . | Apply layer normalization . | Decoder: 6 identical layers. 2 sub layers as above + 1 more which performs multi-head attention over output of encoder stack . | Residual blocks: Present around all 3 sub layers . | Layer normalization: Normalizes input across features instead of normalizing input features across batch dimension(i.e in batch normalization). There is a great overview of normalization layers available by Akash Bindal here. . | Modify self-attention sub layer to prevent positions from attending to subsequent positions. Ensures that i output depends only on words before i. . | . Attention . 3 vectors: Query(Q), Key(K) and Value(V) . | Output = Weighted sum of values. Weights assigned as a function of query with key. . | Scaled dot-product attention and multi-head attention . . | Attention is calculated as: . Attention(Q,K,V)=softmax(QKTdk)VAttention(Q,K,V) = softmax( frac{QK^T}{ sqrt{d_k}})VAttention(Q,K,V)=softmax(dk​​QKT​)V | Dot product attention is faster and more space-efficient than additive attention. . | . Multi head attention . Using multile q, k and v vectors. Get the final output, concatenate them and get another final projection $d_{v}$. . MultiHead(Q,K,V)=Concat(head1,...,headh)WOwhere headi=Attention(QWiQ,KWiK,VWiV)MultiHead(Q,K,V) = Concat(head_1,...,head_h)W^O text{where } head_i = Attention(QW_{i}^{Q}, KW_{i}^{K},VW_{i}^{V})MultiHead(Q,K,V)=Concat(head1​,...,headh​)WOwhere headi​=Attention(QWiQ​,KWiK​,VWiV​) | Dimensions of the key and value matrices will be: $d_{k} = d_{v} = d_{model}/h = 64$ . | . Applications of attention . Encoder-decoder attention: Q from previours decoder, K and V from output of decoder. Attend to all positions in the input sequence. . | Encoder: Self attentnion laters. Q,K and V from output of previous layer in the encoder. Some talk about leftward flow, didn’t really understand this bit. Will come back to this in sometime. . | . Position-wise Feed-Forward Networks . Each layer contains feed-forward network. . FFN(x)=max(o,xW1,+b1)W2+b2FFN(x) = max(o, xW_1,+ b_1)W_2 + b_2FFN(x)=max(o,xW1​,+b1​)W2​+b2​ | . Embeddings and Softmax . Convert input and output string to vectors of dim $d_{model}$ . | Share weight matrix between two embedding layers and the pre-softmaax linear transformation . | . Positional Encoding . Encode positions of the tokens for the input and output. . | Same vector size i.e $d_{model}$ . PE(pos,2i)=sin(pos/100002i/dmodel)PE(pos,2i+1)=cos(pos/100002i/dmodel)PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})PE(pos,2i)​=sin(pos/100002i/dmodel​)PE(pos,2i+1)​=cos(pos/100002i/dmodel​) | Might allow approximation of longer sequence lenghts than seen in the training set . | . Why self attention? . Total computational complexity per layer . | Parallel Computation . | Path length between long-range dependencies in the network. . | . Training . Optimizer . Use Adam. Vary learning rate according to formula: $lrate = d_{model}^{-0.5} . min(step_num^{-0.5}, step_num . warmupsteps^{-1.5})$ . | Increase LR for warmup steps, then decrease propotionally to inverse square root of step number. Warmup steps = 4000 . | . Regularization . Residual Dropout . | Label Smoothing: Instead of using 0 and 1 as class labels, allow for some uncertainity in the prediction, and use values like 0.1 and 0.9 for the classes . | . Conclusion . This was the first model based entirely on attention. It acheived SOTA results on Machine Translation and English contituency parsing. . | Admittedly, there are still a lot of bits I don’t really understand. Specially around self attention. I will give this paper another read after going through Jay Alammar’s blog. . | .",
            "url": "https://goodhamgupta.github.io/blog/nlp/attention/review/2020/04/20/attention.html",
            "relUrl": "/nlp/attention/review/2020/04/20/attention.html",
            "date": " • Apr 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "REALM: Retrieval-Augmented Language MOdel Pre-Training",
            "content": "Introduction . REALM is a paper mentioned in the T5 paper titled: How Much Knowledge Can You Pack Into The Parameters of a Language Model? . | TLDR: This paper retrieves documents that have the information present while solving Question-Answer type problems. . NOTE: This post is more like my running notes while reading the paper than a comprehensive blog. I will update this blog once I learn a little more about the transformer architecture. . | Introduced a latent knowledge retriever, which can attend and retrieve documents over large corpus and can be trained in unsupervised manner using masked language modelling technique and backprop through retreiver which considers lots of docs. . . | Key point: Train retriever using a performance-based signal from unsupervised text. . | Retrieval based LM =&gt; Moar computational resources =&gt; Moar money . Solution: Computation performed for each doc is cached and can be used again. Best doc selected using Maximum Inner Product Search(MIPS). Read the paper here. | . | REALM retriever can be used on downstream tasks via transfer learning. . | REALM is SOTA on NQ-Open, WQ and CuratedTrec. . | . Approach . Retreive-then-predict generative process . Training: Masked-LM. Fine-tuning: Open QA task . | Computing chance of the document given a question decomposed into two steps: . Function to be computed: p(y∥x)p(y |x)p(y∥x) . | Given xxx,retrive documents zzz from corpus ZZZ. Modelled as: p(z∥x)p(z |x)p(z∥x) . | Condition of both zzz and xxx to generate output yyy i.e p(y∥z,x)p(y |z, x)p(y∥z,x) . | Overall likelihood yyy is generated by treating zzz as latent variable and marginalizing over all documents zzz . p(y∥x)=∑zϵZp(y∥z,x)∗p(z∥x)p(y |x) = sum_{z epsilon Z} p(y |z, x) * p(z |x)p(y∥x)=zϵZ∑​p(y∥z,x)∗p(z∥x) | . | . Architecture . Neural Knowledge Retriever which models the distribution: $p(z|x)$ . | Knowledge Augmented Encoder which models the distribution p(y∥z,x)p(y |z, x)p(y∥z,x) . | . Neural Knowledge Retriever . Dense inner product model. . p(z∥x)=exp(f(x,z))∑z′exp(f(x,z′))f(x,z)=Embedinput(x)TEmbeddoc(z) begin{aligned} p(z |x) = frac{exp(f(x,z))}{ sum_{z&amp;#x27;}{exp(f(x,z&amp;#x27;))}} f(x,z) = Embed_{input}(x)^TEmbed_{doc}(z) end{aligned}p(z∥x)=∑z′​exp(f(x,z′))exp(f(x,z))​f(x,z)=Embedinput​(x)TEmbeddoc​(z)​ | EmbedinputEmbed_{input}Embedinput​ and EmbeddocEmbed_{doc}Embeddoc​ are embedding functions . | f(x,z)f(x,z)f(x,z) is called relevance score. It is inner product of vector embeddings. . | Relevant Distribution is softmax over all relevance scores . | Embedding implement using BERT-style transformers. Join using &lt;SEP&gt;, prefix using &lt;CLS&gt; and append &lt;SEP&gt; as the end token. joinBERT(x)=[CLS]x[SEP]joinBERT(x1,x2)=[CLS]x1[SEP]x2[SEP] begin{aligned} join_{BERT}(x) = [CLS]x[SEP] join_{BERT}(x_1, x_2) = [CLS]x_1[SEP]x_2[SEP] end{aligned}joinBERT​(x)=[CLS]x[SEP]joinBERT​(x1​,x2​)=[CLS]x1​[SEP]x2​[SEP]​ . | Pass above into transformer, which gives over vector for each token. Perform linear projection to reduce dimensionality of vector Embedinput(x)=WinputBERTCLS(joinBERT(x))Embeddoc(z)=WdocBERTCLS(joinBERT(ztitle,zbody)) begin{aligned} Embed_{input}(x) = W_{input}BERT_{CLS}(join_{BERT}(x)) Embed_{doc}(z) = W_{doc}BERT_{CLS}(join_{BERT}(z_{title}, z_{body})) end{aligned}Embedinput​(x)=Winput​BERTCLS​(joinBERT​(x))Embeddoc​(z)=Wdoc​BERTCLS​(joinBERT​(ztitle​,zbody​))​ . | . Knowledge-Augmented Encoder . Given input xxx and relevant doc zzz, this defines p(y∥z,x)p(y |z,x)p(y∥z,x) . | Join xxx and zzz into single sequence and feed into transformer . | Here, training is different for pre-training vs fine-tuning . For pre-training, predict [MASK] token. Use same Masked LM(MLM) loss as in Transformer(Devlin et al.) . | For Open-QA, we need to produce string yyy. | Assumption: yyy occurs as sequence of tokens in some document in the corpus. | . | . Training . Compute gradients in θ thetaθ and ϕ phiϕ and optimize using SGD. . | Challenge: Computing p(y∥x)p(y |x)p(y∥x) . | Approx by summing over top kkk documents with highest prob under p(z∥x)p(z |x)p(z∥x) . | Question: How to find top kkk docs? Answer: Use MIPS . | Need to precompute Embeddoc(x)Embed_{doc}(x)Embeddoc​(x) for all docs. Problem? It changes with each step of SGD. . | Solution: Async refresh $Embed_{doc}$ every 500 steps . | Use MIPS to select top $k$ docs. For these docs, recompute $p(z|x)$ using new $ theta$. . | . Implementing async MIPS refreshes . Two jobs running in parallel: . Primary trainer: Perform gradient updates on parameters . | Secondary index builder: Embeds and indexes the docs . . | Async refresh used only for pre-training . | For fine tuning, build index once from pre-trained $ theta$ and use it. . | . | . What does retriever learn? . Retriever promotes docs that improve accuracy . | This can be analyzed by analyzing gradient wrt the parameters . | . Injecting inductive biases into pre-trianing . Salient span masking: Some questions require only local context. Select named entities and dates and mask one of them. Performs better. . | Null document: Add null document to top kkk documents to allow answers even when no context is required . | Prohibiting trivial retrievals: If knowledge corpus ZZZ is the same as pre-training corpus XXX, it can predict yyy by looking at xxx in zzz. Exclude trivial candidate . | Initialization: Warm up EmbedinputEmbed_{input}Embedinput​ and EmbeddocEmbed_{doc}Embeddoc​ using Inverse Cloze Task(ICT) i.e model trained to retrieve the doc where the sentence came from. . | . Experiments . REALM outperforms all approaches by a big margin. | . Future Work . Structured knowledge where we learn entities which are informative . | Multi lingual setting. Retreiving knowledge in high resource language to better represent text in low resource language . | Multi model setting. Retrieve images or videos that can provide knowledge not present in text . | . Comments . Overall, I enjoyed reading this paper. However, there are two key points that concern me: . The authors mention using MIPS for selecting the top kkk documents, in order to simplify the task. However, would selecting only these documents from the entire dataset not lead to some information loss? I would like to see more experiments around this area. | There are no experiments around trying out larger models. While I agree that T5 is the largest model available right now, there is no evidence given that a model larger than T5-large would not perform better than the current REALM model. I would like to see some more exploration around this area. | . Resources . There are a number of other resources you can use to learn more about this paper such as: . The original paper available here | Tweet summary by Adam Roberts available here | Video summary by Václav Košař available here | Huggingface Reading group summary by Joe Davidson available here | .",
            "url": "https://goodhamgupta.github.io/blog/nlp/bert/review/2020/03/14/realm.html",
            "relUrl": "/nlp/bert/review/2020/03/14/realm.html",
            "date": " • Mar 14, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Bayesian Golf Putting Model",
            "content": "Introduction . Disclaimer . This is inspired from Dr. Andrew Gelman&#39;s case study, which can be found here. Specifically: . This is heavily inspired by Colin Caroll&#39;s Blog present here. A lot of the plotting code from his blog post has been reused. | Josh Duncan&#39;s blog post on the same topic which can be found here. | . This is not a novel solution. It is merely a replication of Dr. Gelman&#39;s blog in PyMC3. . Problem . This is based on a popular blog post by Dr. Andrew Gelman. Here, we are given data from professional golfers on the proportion of success putts from a number of tries. Our aim is to identify: . Can we model the probability of success in golf putting as a function of distance from the hole? . EDA . import pandas as pd import numpy as np import pymc3 as pm import matplotlib.pyplot as plt import seaborn as sns . WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions. . The source repository is present here . data = np.array([[2,1443,1346], [3,694,577], [4,455,337], [5,353,208], [6,272,149], [7,256,136], [8,240,111], [9,217,69], [10,200,67], [11,237,75], [12,202,52], [13,192,46], [14,174,54], [15,167,28], [16,201,27], [17,195,31], [18,191,33], [19,147,20], [20,152,24]]) df = pd.DataFrame(data, columns=[ &#39;distance&#39;, &#39;tries&#39;, &#39;success_count&#39; ]) . df . distance tries success_count . 0 2 | 1443 | 1346 | . 1 3 | 694 | 577 | . 2 4 | 455 | 337 | . 3 5 | 353 | 208 | . 4 6 | 272 | 149 | . 5 7 | 256 | 136 | . 6 8 | 240 | 111 | . 7 9 | 217 | 69 | . 8 10 | 200 | 67 | . 9 11 | 237 | 75 | . 10 12 | 202 | 52 | . 11 13 | 192 | 46 | . 12 14 | 174 | 54 | . 13 15 | 167 | 28 | . 14 16 | 201 | 27 | . 15 17 | 195 | 31 | . 16 18 | 191 | 33 | . 17 19 | 147 | 20 | . 18 20 | 152 | 24 | . The variables have the following format: . Variable Units Description . distance | feet | Distance from the hole for the putt attempt | . tries | count | Number of attempts at the chosen distance | . success_count | count | The total successful putts | . Lets try to visualize the dataset: . df[&#39;success_prob&#39;] = df.success_count / df.tries . sns.set() plt.figure(figsize=(16, 6)) ax = sns.scatterplot(x=&#39;distance&#39;, y=&#39;success_prob&#39;, data=df, s=200) ax.set(xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39;) . [Text(0, 0.5, &#39;Probability of Success&#39;), Text(0.5, 0, &#39;Distance from hole(ft)&#39;)] . We can notice that the probability of success decreases as the distance increases. . Baseline Model . Let us try to see we can fit a simple linear model to the data i.e Logsitic Regression. We will be using PyMC3. . Here, we will attempt to model the success of golf putting by using the distance as an independant(i.e predictor) variable. The model will have the following form: . $$y_i sim binomial(n_j, logit^{-1}(b_0 + b_1x_j)), text{for } j = 1,...J $$ . with pm.Model() as model: b_0 = pm.Normal(&#39;b_0&#39;, mu=0, sd=1) b_1 = pm.Normal(&#39;b_1&#39;, mu=0, sd=1) y = pm.Binomial( &#39;y&#39;, n=df.tries, p=pm.math.invlogit(b_0 + b_1 * df.distance), observed=df.success_count ) . Why are we using inverse logit? . Logit is a function used to convert a continous variable to a value in the range [0,1] | Inverse Logit: Used to convert real valued variable to a value in the range [0,1] | . pm.model_to_graphviz(model) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster19 19 b_0 b_0 ~ Normal y y ~ Binomial b_0&#45;&gt;y b_1 b_1 ~ Normal b_1&#45;&gt;y with model: trace = pm.sample(1000, tune=1000, chains=4) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 2 jobs) NUTS: [b_1, b_0] Sampling 4 chains, 0 divergences: 100%|██████████| 8000/8000 [00:06&lt;00:00, 1164.22draws/s] The acceptance probability does not match the target. It is 0.889539212527967, but should be close to 0.8. Try to increase the number of tuning steps. The acceptance probability does not match the target. It is 0.6968711559119489, but should be close to 0.8. Try to increase the number of tuning steps. The number of effective samples is smaller than 25% for some parameters. . pm.summary(trace)[[&#39;mean&#39;, &#39;sd&#39;, &#39;mcse_mean&#39;, &#39;mcse_sd&#39;, &#39;ess_mean&#39;, &#39;r_hat&#39;]] . mean sd mcse_mean mcse_sd ess_mean r_hat . b_0 2.226 | 0.060 | 0.002 | 0.001 | 926.0 | 1.01 | . b_1 -0.255 | 0.007 | 0.000 | 0.000 | 838.0 | 1.01 | . pm.traceplot(trace) . array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfef7cfd68&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfef77efd0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfef848828&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfef758a58&gt;]], dtype=object) . pm.plot_posterior(trace) . array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfedd70be0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfedd2a860&gt;], dtype=object) . From the above results, we can see: . PyMC3 has estimated $b_0$ to be $2.23 pm 0.057$ | $b_1$ to be $-0.26 pm 0.007$ | . | The MCSE is almost 0 $ implies$ The simulation has run long enough for the chains to converge. | $r _hat = 1.0$ tells us that the chains have mixed well i.e hairy hedgehog pattern. | . Let us plot the final output of this model and check it with our training data. . with model: posterior_trace = pm.sample_posterior_predictive(trace) . 100%|██████████| 4000/4000 [00:04&lt;00:00, 888.12it/s] . posterior_success = posterior_trace[&#39;y&#39;] / df.tries.values . df[&#39;posterior_success_prob&#39;] = pd.DataFrame(posterior_success).median() df[&#39;posterior_success_prob_std&#39;] = pd.DataFrame(posterior_success).std() . sns.set() plt.figure(figsize=(16, 6)) prob = df.success_count/df.tries ax = sns.scatterplot(x=&#39;distance&#39;, y=df.success_prob, data=df, s=200, label=&#39;actual&#39;) # ls = np.linspace(0, df.distance.max(), 200) # for index in np.random.randint(0, len(trace), 50): # ax.plot( # ls, # scipy.special.expit( # trace[&#39;b_0&#39;][index] * ls + trace[&#39;b_1&#39;][index] * ls # ) # ) sns.scatterplot(x=&#39;distance&#39;, y=df.posterior_success_prob, data=df, label=&#39;predicted&#39;,ax=ax, color=&#39;red&#39;, s=200) sns.lineplot(x=&#39;distance&#39;, y=df.posterior_success_prob, data=df,ax=ax, color=&#39;red&#39;) ax.set(xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39;) . [Text(0, 0.5, &#39;Probability of Success&#39;), Text(0.5, 0, &#39;Distance from hole(ft)&#39;)] . The curve fit is okay, but it can be improved. We can use this as a baseline model. In reality, each of them is not a point, but an posterior estimate. Because the uncertainity is small(as seen above), we&#39;ve decided to show only the median points. . From the above model, putts from 50ft are expected to be made with probability: . import scipy res = 100 * scipy.special.expit(2.223 + -0.255 * 50).mean() print(np.round(res, 5),&quot;%&quot;) . 0.00268 % . Modelling from first principles . Geometry based Model . . We&#39;ll try to accomodate the physics associated with the problem. Specically, we assume: . Assumptions . The golfers can hit the ball in any direction with some small error. This error could be because of inaccuracy, errors in the human, etc. | This error refers to the angle of the shot. | We assume the angle is normally distributed. | . Implications . The ball goes in whenever the angle is small enough for it to hit the cup of the hole! | Longer putt $ implies$ Larger error $ implies$ Lower success rate than shorter putt | . From Dr. Gelman&#39;s blog, we obtain the formula as: . $Pr(|angle| &lt; sin^{-1}( frac{(R-r)}{x})) = 2 phi big( frac{sin^{-1} frac{R-r}{x}}{ sigma} big) - 1$ . $ phi implies$ Cumulative Normal Distribution Function. . Hence, our model will now have two big parts: . $$y_j sim binomial(n_j, p_j)$$ . $$p_j = 2 phi big( frac{sin^{-1} frac{R-r}{x}}{ sigma} big) - 1$$ . Typically, the diameter of a golf ball is 1.68 inches and the cup is 4.25 inches i.e . $$r = 1.68 text{inch}$$ $$R = 4.25 text{inch}$$ . ball_radius = (1.68/2)/12 cup_radius = (4.25/2)/12 . def calculate_prob(angle, distance): &quot;&quot;&quot; Calculate probability that the ball with fall in the hole given the angle of the shot and the distance from the hole. &quot;&quot;&quot; rad = angle * np.pi / 180.0 arcsin = np.arcsin((cup_radius - ball_radius)/ distance) return 2 * scipy.stats.norm(0, rad).cdf(arcsin) - 1 . plt.figure(figsize=(16, 6)) ls = np.linspace(0, df.distance.max(), 200) ax = sns.scatterplot( x=&#39;distance&#39;, y=&#39;success_prob&#39;, data=df, s=100, legend=&#39;full&#39; ) for angle in [0.5, 1, 2, 5, 20]: ax.plot( ls, calculate_prob(angle, ls), label=f&quot;Angle={angle}&quot; ) ax.set( xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39; ) ax.legend() . &lt;matplotlib.legend.Legend at 0x7fdfed1ee898&gt; . Let us now add this to our model! . import theano.tensor as tt def calculate_phi(num): &quot;cdf for standard normal&quot; q = tt.erf(num / tt.sqrt(2.0)) # ERF is the Gaussian Error return (1.0 + q) / 2. . with pm.Model() as model: angle_of_shot_radians = pm.HalfNormal(&#39;angle_of_shot_radians&#39;) angle_of_shot_degrees = pm.Deterministic( &#39;angle_of_shot_degrees&#39;, (angle_of_shot_radians * 180.0) / np.pi ) p_ball_goes_in = pm.Deterministic( &#39;p_ball_goes_in&#39;, 2 * calculate_phi( tt.arcsin( (cup_radius - ball_radius)/ df.distance ) / angle_of_shot_radians ) ) - 1 p_success = pm.Binomial( &#39;p_success&#39;, n=df.tries, p=p_ball_goes_in, observed=df.success_count ) . pm.model_to_graphviz(model) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster19 19 angle_of_shot_degrees angle_of_shot_degrees ~ Deterministic angle_of_shot_radians angle_of_shot_radians ~ HalfNormal angle_of_shot_radians&#45;&gt;angle_of_shot_degrees p_ball_goes_in p_ball_goes_in ~ Deterministic angle_of_shot_radians&#45;&gt;p_ball_goes_in p_success p_success ~ Binomial p_ball_goes_in&#45;&gt;p_success with model: trace = pm.sample(4000, tune=1000, chains=4) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... ERROR (theano.gof.opt): Optimization failure due to: local_grad_log_erfc_neg ERROR (theano.gof.opt): node: Elemwise{true_div}(Elemwise{mul,no_inplace}.0, Elemwise{erfc,no_inplace}.0) ERROR (theano.gof.opt): TRACEBACK: ERROR (theano.gof.opt): Traceback (most recent call last): File &#34;/home/goodhamgupta/shubham/blog/_notebooks/.env/lib/python3.6/site-packages/theano/gof/opt.py&#34;, line 2034, in process_node replacements = lopt.transform(node) File &#34;/home/goodhamgupta/shubham/blog/_notebooks/.env/lib/python3.6/site-packages/theano/tensor/opt.py&#34;, line 6789, in local_grad_log_erfc_neg if not exp.owner.inputs[0].owner: AttributeError: &#39;NoneType&#39; object has no attribute &#39;owner&#39; Multiprocess sampling (4 chains in 2 jobs) NUTS: [angle_of_shot_radians] Sampling 4 chains, 0 divergences: 100%|██████████| 20000/20000 [00:10&lt;00:00, 1943.54draws/s] The acceptance probability does not match the target. It is 0.8844154441842546, but should be close to 0.8. Try to increase the number of tuning steps. . pm.summary(trace).head(2) . mean sd hpd_3% hpd_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat . angle_of_shot_radians 0.027 | 0.000 | 0.026 | 0.027 | 0.0 | 0.0 | 6641.0 | 6641.0 | 6641.0 | 10874.0 | 1.0 | . angle_of_shot_degrees 1.527 | 0.023 | 1.484 | 1.570 | 0.0 | 0.0 | 6641.0 | 6641.0 | 6641.0 | 10874.0 | 1.0 | . pm.plot_posterior(trace[&#39;angle_of_shot_degrees&#39;]) . array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdfe4c24f60&gt;], dtype=object) . From the above results, we can see: . PyMC3 has estimated $angle_of_shot_degrees$ to be $1.53 pm 0.023$ | . | The MCSE is almost 0 $ implies$ The simulation has run long enough for the chains to converge. | $r _hat = 1.0$ tells us that the chains have mixed well i.e hairy hedgehog pattern. | . Let&#39;s visualize the fit with this new model: . geo_model_prob = calculate_prob( trace[&#39;angle_of_shot_degrees&#39;].mean(), df.distance ) . sns.set() plt.figure(figsize=(16, 6)) ax = sns.scatterplot(x=&#39;distance&#39;, y=df.success_prob, data=df, s=200, label=&#39;Actual&#39;) sns.scatterplot(x=&#39;distance&#39;, y=df.posterior_success_prob, data=df, label=&#39;Logistic Regression&#39;,ax=ax, color=&#39;red&#39;, s=100) sns.scatterplot(x=&#39;distance&#39;, y=geo_model_prob, data=df, label=&#39;Geometry based &#39;,ax=ax, color=&#39;orange&#39;, s=100) sns.lineplot(x=&#39;distance&#39;, y=df.posterior_success_prob, data=df,ax=ax, color=&#39;red&#39;) sns.lineplot(x=&#39;distance&#39;, y=geo_model_prob, data=df,ax=ax, color=&#39;orange&#39;) ax.set(xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39;) . [Text(0, 0.5, &#39;Probability of Success&#39;), Text(0.5, 0, &#39;Distance from hole(ft)&#39;)] . We can see that the geometry based model fits better than the logistic regression model. | While this model is not completely accurate, it suggests that angle is a good variable to model the problem. Using this model, we can be more confident about extrapolating the data. | For the same 50ft putt, the probability now is: | . import scipy lr_result = np.round( 100 * scipy.special.expit(2.223 + -0.255 * 50).mean(), 5 ) geo_result = np.round( 100 * calculate_prob( trace[&#39;angle_of_shot_degrees&#39;].mean(), 50 ).mean(), 5 ) print( f&quot;Logistic Regression Model: {lr_result}% n&quot; f&quot;Geometry Based Model: {geo_result}%&quot; ) . Logistic Regression Model: 0.00268% Geometry Based Model: 6.40322% . New Data! . Mark Broadie obtained new data about the golfers. Let&#39;s see how our model performs on this new dataset. . First, we&#39;ll look at the summary of the dataset. . # golf putting data from Broadie (2018) new_golf_data = np.array([ [0.28, 45198, 45183], [0.97, 183020, 182899], [1.93, 169503, 168594], [2.92, 113094, 108953], [3.93, 73855, 64740], [4.94, 53659, 41106], [5.94, 42991, 28205], [6.95, 37050, 21334], [7.95, 33275, 16615], [8.95, 30836, 13503], [9.95, 28637, 11060], [10.95, 26239, 9032], [11.95, 24636, 7687], [12.95, 22876, 6432], [14.43, 41267, 9813], [16.43, 35712, 7196], [18.44, 31573, 5290], [20.44, 28280, 4086], [21.95, 13238, 1642], [24.39, 46570, 4767], [28.40, 38422, 2980], [32.39, 31641, 1996], [36.39, 25604, 1327], [40.37, 20366, 834], [44.38, 15977, 559], [48.37, 11770, 311], [52.36, 8708, 231], [57.25, 8878, 204], [63.23, 5492, 103], [69.18, 3087, 35], [75.19, 1742, 24], ]) new_df = pd.DataFrame( new_golf_data, columns=[&#39;distance&#39;, &#39;tries&#39;, &#39;success_count&#39;] ) . new_geo_model_prob = calculate_prob( trace[&#39;angle_of_shot_degrees&#39;].mean(), new_df.distance ) . new_df[&#39;success_prob&#39;] = new_df.success_count / new_df.tries sns.set() plt.figure(figsize=(16, 6)) ax = sns.scatterplot(x=&#39;distance&#39;, y=&#39;success_prob&#39;, data=df, label=&#39;Old Dataset&#39;, s=200) sns.scatterplot(x=&#39;distance&#39;, y=&#39;success_prob&#39;, data=new_df,label=&#39;New Dataset&#39;, s=200, ax=ax) sns.scatterplot(x=&#39;distance&#39;, y=new_geo_model_prob, data=new_df, label=&#39;Geometry based Model &#39;,ax=ax, color=&#39;red&#39;, s=100) ax.set( xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39; ) plt.setp(ax.get_legend().get_texts(), fontsize=&#39;25&#39;) . [None, None, None, None, None, None] . We can see: . Success rate is similar in the 0-20 feet range for both datasets. | Beyond 20 ft, success rate is lower than expected. These attempts are more difficult, even after we have accounted for increased angular precision. | . Moar features! . To get the ball in, along with the angle, we should also need to take into account if the ball was hit hard enough. . From Colin Caroll&#39;s Blog, we have the following: . Mark Broadie made the following assumptions . If a putt goes short or more than 3 feet past the hole, it will not go in. | Golfers aim for 1 foot past the hole | The distance the ball goes, $u$, is distributed as:$$ u sim mathcal{N} left(1 + text{distance}, sigma_{ text{distance}} (1 + text{distance}) right), $$ where we will learn $ sigma_{ text{distance}}$. After working through the geometry and algebra, we get: | . $$P( text{Good shot}) = bigg(2 phi big( frac{sin^{-1}( frac{R-r}{x})}{ sigma_{angle}} big)-1 bigg) bigg( phi bigg( frac{2}{(x+1) sigma_{distance}} bigg) - phi bigg( frac{-1}{(x+1) sigma_{distance}} bigg) bigg)$$ . Let&#39;s write this down in PyMC3 . OVERSHOT = 1.0 DISTANCE_TOLERANCE = 3.0 distances = new_df.distance.values with pm.Model() as model: angle_of_shot_radians = pm.HalfNormal(&#39;angle_of_shot_radians&#39;) angle_of_shot_degrees = pm.Deterministic( &#39;angle_of_shot_degrees&#39;, (angle_of_shot_radians * 180.0) / np.pi ) variance_of_distance = pm.HalfNormal(&#39;variance_of_distance&#39;) p_good_angle = pm.Deterministic( &#39;p_good_angle&#39;, 2 * calculate_phi( tt.arcsin( (cup_radius - ball_radius)/ distances ) / angle_of_shot_radians ) ) - 1 p_good_distance = pm.Deterministic( &#39;p_good_distance&#39;, calculate_phi( (DISTANCE_TOLERANCE - OVERSHOT) / ((distances + OVERSHOT) * variance_of_distance)) - calculate_phi( -OVERSHOT / ((distances + OVERSHOT) * variance_of_distance)) ) p_success = pm.Binomial( &#39;p_success&#39;, n=new_df.tries, p=p_good_angle * p_good_distance, observed=new_df.success_count ) . pm.model_to_graphviz(model) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; %3 cluster31 31 angle_of_shot_degrees angle_of_shot_degrees ~ Deterministic variance_of_distance variance_of_distance ~ HalfNormal p_good_distance p_good_distance ~ Deterministic variance_of_distance&#45;&gt;p_good_distance angle_of_shot_radians angle_of_shot_radians ~ HalfNormal angle_of_shot_radians&#45;&gt;angle_of_shot_degrees p_good_angle p_good_angle ~ Deterministic angle_of_shot_radians&#45;&gt;p_good_angle p_success p_success ~ Binomial p_good_angle&#45;&gt;p_success p_good_distance&#45;&gt;p_success with model: trace = pm.sample(1000, tune=1000, chains=4) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 2 jobs) NUTS: [variance_of_distance, angle_of_shot_radians] Sampling 4 chains, 0 divergences: 100%|██████████| 8000/8000 [00:08&lt;00:00, 969.28draws/s] The number of effective samples is smaller than 25% for some parameters. . pm.summary(trace).head(3) . mean sd hpd_3% hpd_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat . angle_of_shot_radians 0.013 | 0.000 | 0.013 | 0.013 | 0.0 | 0.0 | 865.0 | 865.0 | 862.0 | 1109.0 | 1.0 | . angle_of_shot_degrees 0.761 | 0.003 | 0.755 | 0.768 | 0.0 | 0.0 | 865.0 | 865.0 | 862.0 | 1109.0 | 1.0 | . variance_of_distance 0.137 | 0.001 | 0.136 | 0.138 | 0.0 | 0.0 | 855.0 | 855.0 | 855.0 | 1186.0 | 1.0 | . pm.plot_posterior(trace[&#39;variance_of_distance&#39;]) . array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fdff74693c8&gt;], dtype=object) . with model: distance_posterior = pm.sample_posterior_predictive(trace) . 100%|██████████| 4000/4000 [00:04&lt;00:00, 846.25it/s] . def calculate_prob_distance(angle, distance, ls): &quot;&quot;&quot; Calculate the probability the ball will land inside the hole given the variance in angle and distance. NOTE: Adapted from Colin Carroll&#39;s Blog. &quot;&quot;&quot; norm = scipy.stats.norm(0, 1) prob_angle = 2 * norm.cdf( np.arcsin((cup_radius - ball_radius) / ls) / angle) - 1 prob_distance_one = norm.cdf( (DISTANCE_TOLERANCE - OVERSHOT) / ((ls + OVERSHOT) * distance) ) prob_distance_two = norm.cdf(-OVERSHOT / ((ls + OVERSHOT) * distance)) prob_distance = prob_distance_one - prob_distance_two return prob_angle * prob_distance . ls = np.linspace(0, new_df.distance.max(), 200) . new_df[&#39;success_prob&#39;] = new_df.success_count / new_df.tries sns.set() plt.figure(figsize=(16, 6)) ax = sns.scatterplot( x=&#39;distance&#39;, y=&#39;success_prob&#39;, data=new_df, label=&#39;Actual&#39;, s=200 ) sns.scatterplot( x=&#39;distance&#39;, y=new_geo_model_prob, data=new_df, label=&#39;Angle only Model&#39;, ax=ax, color=&#39;red&#39;, s=100 ) sns.scatterplot( x=&#39;distance&#39;, y=calculate_prob_distance( trace[&#39;angle_of_shot_radians&#39;].mean(), trace[&#39;variance_of_distance&#39;].mean(), new_df.distance ), data=new_df, label=&#39;Distance + Angle based Model &#39;, ax=ax, color=&#39;black&#39;, s=100 ) ax.set( xlabel=&#39;Distance from hole(ft)&#39;, ylabel=&#39;Probability of Success&#39; ) plt.setp(ax.get_legend().get_texts(), fontsize=&#39;25&#39;) . [None, None, None, None, None, None] . From the graph, we can conclude that: . The model is good at distance lower than 10 ft and distances higher than 40ft. | There is some mismatch between 10ft to 40ft, but overall this is a good fit. | . What&#39;s the point? . Using Bayesian analysis, we want to be able to quantify the unvertainity with each of our predictions. Since each prediction is a distribution, we can utilize this to see where the putts will fall if they do not fall in the hole. . def simulate_from_distance(trace, distance_to_hole, trials=10_000): n_samples = trace[&#39;angle_of_shot_radians&#39;].shape[0] idxs = np.random.randint(0, n_samples, trials) variance_of_shot = trace[&#39;angle_of_shot_radians&#39;][idxs] variance_of_distance = trace[&#39;variance_of_distance&#39;][idxs] theta = np.random.normal(0, variance_of_shot) distance = np.random.normal(distance_to_hole + OVERSHOT, (distance_to_hole + OVERSHOT) * variance_of_distance) final_position = np.array([distance * np.cos(theta), distance * np.sin(theta)]) made_it = np.abs(theta) &lt; np.arcsin((cup_radius - ball_radius) / distance_to_hole) made_it = made_it * (final_position[0] &gt; distance_to_hole) * (final_position[0] &lt; distance_to_hole + DISTANCE_TOLERANCE) _, ax = plt.subplots() ax.plot(0, 0, &#39;k.&#39;, lw=1, mfc=&#39;black&#39;, ms=150 / distance_to_hole) ax.plot(*final_position[:, ~made_it], &#39;.&#39;, alpha=0.1, mfc=&#39;r&#39;, ms=250 / distance_to_hole, mew=0.5) ax.plot(distance_to_hole, 0, &#39;ko&#39;, lw=1, mfc=&#39;black&#39;, ms=350 / distance_to_hole) ax.set_facecolor(&quot;#e6ffdb&quot;) ax.set_title(f&quot;Final position of {trials:,d} putts from {distance_to_hole}ft. n({100 * made_it.mean():.1f}% made)&quot;) return ax simulate_from_distance(trace, distance_to_hole=10); . Conclusion . We&#39;ve just seen how incorporate subjective knowledge in our models and help them fit cases that are specific to our use-case. . References: . This is heavily inspired by Colin Caroll&#39;s Blog present here | The crux of this post is based on Dr. Gelman&#39;s case study present here. | .",
            "url": "https://goodhamgupta.github.io/blog/jupyter/bayesian/golf_putting/2020/03/12/tutorial.html",
            "relUrl": "/jupyter/bayesian/golf_putting/2020/03/12/tutorial.html",
            "date": " • Mar 12, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "First Post",
            "content": "Yo! . Super excited to finally get my own blog. Hope to write out those long pending articles ASAP now. Stay tuned! .",
            "url": "https://goodhamgupta.github.io/blog/intro/2020/01/14/first-post.html",
            "relUrl": "/intro/2020/01/14/first-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! I’m Shubham Gupta. Through this blog, I aim to talk a little bit about my current work and potential topics I’m interested in learning. Some of my main projects are available here: . Snowplow Elixir Tracker | Paper Reviews | Doing Bayesian Data Analysis: Notes and Solutions | . You can learn more about my work and contribute on GitHub. .",
          "url": "https://goodhamgupta.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}